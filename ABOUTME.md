I am A multimodal systems thinker who can bridge perception → world modeling → reasoning → action.

I want to be seen as someone who can contribute to:

Vision-language models
World models
Embodied agents
Multimodal reasoning
Real-world grounding
Agentic planning

My edge is 

Closed-loop learning
Embodied memory
Spatial reasoning


Meta’s superintelligence direction will likely include:

Multimodal foundation models
Agents that act in the world
Memory & long-horizon reasoning
Simulation-based training
Embodied AI



Explain large-scale training bottlenecks from first principles
Derive KV cache memory growth on a whiteboard
Design a 10k–20k GPU training run
Critique Transformer scaling limits
Articulate one strong original insight