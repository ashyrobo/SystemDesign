# ðŸ§  Applied ML Interview Memory Bank

> **Your centralized knowledge index for Seniorâ†’Staff Applied ML interviews**

This memory bank provides instant access to all concepts, cross-references, progress tracking, and quick lookups across your interview prep materials.

## ðŸ—‚ï¸ Knowledge Index

### [ðŸ“š Foundations (00-foundations/)](./00-foundations/)
*Core ML concepts and mathematical foundations*

| Topic | File | Status | Key Concepts |
|-------|------|--------|--------------|
| Statistics & Probability | `statistical-foundations.md` | â³ Planned | Distributions, hypothesis testing, Bayesian inference |
| Linear Algebra | `linear-algebra.md` | â³ Planned | Matrices, eigenvalues, SVD, PCA |
| Optimization | `optimization-theory.md` | â³ Planned | Gradient descent, convex optimization, constraints |
| Information Theory | `information-theory.md` | â³ Planned | Entropy, mutual information, KL divergence |

### [ðŸŽ¯ Supervised Learning (01-supervised-learning/)](./01-supervised-learning/)
*Classification, regression, and evaluation methods*

| Topic | File | Status | Key Concepts |
|-------|------|--------|--------------|
| Classification | `classification-methods.md` | â³ Planned | Logistic regression, SVM, decision trees |
| Regression | `regression-analysis.md` | â³ Planned | Linear/polynomial regression, regularization |
| Model Selection | `model-selection.md` | â³ Planned | Cross-validation, bias-variance tradeoff |
| Metrics & Evaluation | `evaluation-metrics.md` | â³ Planned | Precision, recall, ROC, calibration |
| Feature Engineering | `feature-engineering.md` | â³ Planned | Selection, scaling, encoding, interactions |
| Bias & Fairness | `bias-fairness.md` | â³ Planned | Demographic parity, equalized odds, calibration |
| Cold Start Problem | `cold-start.md` | â³ Planned | New user/item recommendations, hybrid approaches |
| Recommendation Metrics | `recommendation-metrics.md` | â³ Planned | NDCG, MAP, diversity, coverage |

### [ðŸ§  Deep Learning (02-deep-learning/)](./02-deep-learning/)
*Neural networks, architectures, and optimization*

| Topic | File | Status | Key Concepts |
|-------|------|--------|--------------|
| Neural Networks | `neural-networks-basics.md` | â³ Planned | Backpropagation, activation functions, initialization |
| CNN Architectures | `convolutional-networks.md` | â³ Planned | ResNet, DenseNet, attention mechanisms |
| RNN & Transformers | `sequence-models.md` | â³ Planned | LSTM, GRU, attention, BERT, GPT |
| Learning to Rank | `learning-to-rank.md` | â³ Planned | Pointwise, pairwise, listwise approaches |
| Fine-tuning | `transfer-learning.md` | â³ Planned | Pre-training, adaptation, catastrophic forgetting |
| Model Calibration | `model-calibration.md` | â³ Planned | Temperature scaling, Platt scaling, reliability |

### [âš™ï¸ ML Systems (03-ml-systems/)](./03-ml-systems/)
*Production ML infrastructure and operations*

| Topic | File | Status | Key Concepts |
|-------|------|--------|--------------|
| Model Serving | `model-serving.md` | â³ Planned | REST APIs, batch/online inference, caching |
| Feature Stores | `feature-stores.md` | â³ Planned | Real-time features, consistency, versioning |
| A/B Testing | `ab-testing-ml.md` | â³ Planned | Randomization, statistical power, guardrails |
| Monitoring & Alerting | `ml-monitoring.md` | â³ Planned | Drift detection, performance degradation, SLAs |
| Data Pipelines | `data-engineering.md` | â³ Planned | ETL, streaming, data quality, lineage |
| Model Training | `training-pipelines.md` | â³ Planned | Distributed training, hyperparameter tuning |
| MLOps | `mlops-practices.md` | â³ Planned | CI/CD for ML, model versioning, rollback |

### [ðŸ“Š Math Derivations (04-math-derivations/)](./04-math-derivations/)
*Mathematical foundations and proofs*

| Topic | File | Status | Key Concepts |
|-------|------|--------|--------------|
| Loss Functions | `loss-function-derivations.md` | â³ Planned | Cross-entropy, hinge loss, focal loss |
| Optimization | `gradient-descent-variants.md` | â³ Planned | SGD, Adam, RMSprop, learning rate schedules |
| Regularization | `regularization-theory.md` | â³ Planned | L1/L2, dropout, batch normalization |
| Probabilistic Models | `bayesian-inference.md` | â³ Planned | MAP, MLE, variational inference |

### [â“ Interview Questions (05-common-interview-questions/)](./05-common-interview-questions/)
*Frequently asked questions and answer patterns*

| Topic | File | Status | Key Concepts |
|-------|------|--------|--------------|
| Problem Framing | `problem-framing-questions.md` | â³ Planned | Business metrics, success criteria, constraints |
| Model Selection | `model-choice-questions.md` | â³ Planned | Algorithm comparison, trade-offs, justification |
| Debugging | `debugging-scenarios.md` | â³ Planned | Performance drops, data issues, system failures |
| System Design | `ml-system-design.md` | â³ Planned | Architecture patterns, scalability, reliability |

### [ðŸ“ Case Studies (06-case-studies/)](./06-case-studies/)
*Real-world FAANG-scale ML systems*

| System | File | Status | Scale | Key Focus Areas |
|--------|------|--------|-------|-----------------|
| Netflix Recommendations | `netflix-recommendation-ranking.md` | âœ… Complete | 200M users | Two-tower, cold start, position bias, A/B testing |
| Meta Fraud Detection | `meta-fraud-detection.md` | âœ… Complete | Billions/day | Ensemble methods, adversarial ML, class imbalance |
| Google Search Relevance | `google-search-relevance.md` | âœ… Complete | 8B queries/day | BERT, learning-to-rank, distributed systems |

## ðŸ”— Cross-Reference Map

### ðŸŽ¯ Problem Type â†’ Solutions
```mermaid
graph TD
    A[Classification Problems] --> B[Imbalanced Data]
    A --> C[Multi-class]
    A --> D[Multi-label]
    
    B --> E[SMOTE, Class Weights]
    B --> F[Focal Loss, Cost-sensitive]
    
    G[Recommendation Systems] --> H[Cold Start]
    G --> I[Scalability] 
    G --> J[Diversity]
    
    H --> K[Content-based, Demographic]
    I --> L[Two-tower, Candidate Generation]
    J --> M[MMR, Diversity Penalties]
```

### ðŸ”§ System Component â†’ Implementation
- **Model Serving**: Feature Stores + Model Registry + Caching
- **A/B Testing**: Randomization + Metrics + Statistical Testing
- **Monitoring**: Drift Detection + Performance Tracking + Alerting
- **Data Pipeline**: ETL + Quality Checks + Lineage Tracking

### ðŸ“Š Metric Type â†’ Use Cases
- **Business Metrics**: Revenue, retention, engagement, conversion
- **ML Metrics**: Accuracy, precision, recall, F1, AUC, NDCG
- **System Metrics**: Latency, throughput, availability, cost
- **Fairness Metrics**: Demographic parity, equalized odds, calibration

## ðŸ“ˆ Progress Tracker

### Learning Path Completion
- [ ] **Foundations Complete** (0/4 topics)
- [ ] **Supervised Learning Complete** (0/8 topics)  
- [ ] **Deep Learning Complete** (0/6 topics)
- [ ] **ML Systems Complete** (0/7 topics)
- [ ] **Math Derivations Complete** (0/4 topics)
- [ ] **Interview Questions Complete** (0/4 topics)
- [x] **Case Studies Complete** (3/3 topics) âœ…

### Interview Readiness Checklist
- [ ] Can explain business impact of ML decisions
- [ ] Familiar with FAANG-scale system constraints  
- [ ] Can debug ML system failures systematically
- [ ] Understands trade-offs between model complexity and serving
- [ ] Can design end-to-end ML systems from scratch
- [ ] Familiar with A/B testing and experimentation
- [ ] Understands bias, fairness, and responsible ML
- [ ] Can derive key ML algorithms from first principles

## ðŸš€ Quick Reference

### Must-Know Algorithms
| Algorithm | Use Case | Pros | Cons | Implementation Notes |
|-----------|----------|------|------|---------------------|
| Logistic Regression | Binary classification | Fast, interpretable | Linear boundaries | Use regularization for high-dim |
| Random Forest | Tabular data | Handles missing values | Can overfit | Use for feature importance |
| Gradient Boosting | Ranking, regression | High performance | Slow training | XGBoost/LightGBM preferred |
| Neural Networks | Image, text, complex patterns | Universal approximator | Data hungry | Use pre-trained when possible |

### Key Metrics by Problem Type
| Problem Type | Primary Metrics | Secondary Metrics | Business Metrics |
|--------------|-----------------|-------------------|------------------|
| Classification | Precision, Recall, F1 | ROC-AUC, Calibration | Conversion rate, Cost per error |
| Regression | MAE, RMSE | MAPE, RÂ² | Revenue impact, Customer satisfaction |
| Ranking | NDCG, MAP | MRR, Precision@K | Click-through rate, Session time |
| Recommendation | CTR, Coverage | Diversity, Freshness | Retention, Discovery rate |

### System Design Patterns
| Pattern | When to Use | Key Components | Scale Considerations |
|---------|-------------|----------------|---------------------|
| Batch Prediction | Daily/weekly updates OK | Scheduled jobs, data warehouse | Cost-effective, high throughput |
| Real-time Serving | <100ms response needed | Model servers, caching, load balancing | High availability, low latency |
| Hybrid Architecture | Mixed requirements | Batch + real-time components | Complexity vs flexibility trade-off |

### Debugging Playbook
1. **Performance Drop**: Check data drift â†’ model staleness â†’ feature pipeline â†’ A/B test interference
2. **Latency Spike**: Check model serving â†’ database connections â†’ caching â†’ network issues  
3. **Accuracy Regression**: Verify training data â†’ feature engineering â†’ hyperparameters â†’ evaluation methodology
4. **Business Impact**: Align ML metrics with business KPIs â†’ segment analysis â†’ long-term effects

## ðŸŽ“ Interview Preparation Strategy

### Week 1-2: Foundations
- [ ] Complete statistical foundations and linear algebra
- [ ] Master evaluation metrics and model selection
- [ ] Practice problem framing exercises

### Week 3-4: Deep Dive
- [ ] Study case studies thoroughly (Netflix, Meta, Google)
- [ ] Practice system design questions
- [ ] Learn debugging methodologies

### Week 5-6: Advanced Topics  
- [ ] ML systems architecture and scalability
- [ ] A/B testing and experimentation
- [ ] Bias, fairness, and responsible ML

### Week 7-8: Mock Interviews
- [ ] Practice with peers or platforms
- [ ] Focus on communication and trade-off discussions
- [ ] Time yourself on problem-solving

---

*Last Updated: 2025-02-19 | Next Review: Weekly*