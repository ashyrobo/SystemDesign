# ğŸš€ Quick Reference Guide

> **Instant access to key concepts, formulas, and decision frameworks for ML interviews**

## ğŸ“Š Essential Metrics Cheatsheet

### Classification Metrics
```
Precision = TP / (TP + FP)    # Of predicted positive, how many are correct?
Recall    = TP / (TP + FN)    # Of actual positive, how many did we find?
F1 Score  = 2 * (P * R) / (P + R)
Accuracy  = (TP + TN) / (TP + TN + FP + FN)

ROC-AUC: Area under ROC curve (TPR vs FPR)
PR-AUC:  Area under Precision-Recall curve
```

### Regression Metrics
```
MAE  = Î£|y_true - y_pred| / n     # Mean Absolute Error
RMSE = âˆš(Î£(y_true - y_pred)Â² / n) # Root Mean Square Error  
MAPE = Î£|y_true - y_pred|/|y_true| / n * 100  # Mean Absolute Percentage Error
RÂ²   = 1 - SS_res/SS_tot          # Coefficient of Determination
```

### Ranking Metrics
```
NDCG@k = DCG@k / IDCG@k
DCG@k  = Î£(2^rel_i - 1) / logâ‚‚(i + 1)  # Discounted Cumulative Gain
MAP    = Î£(P@k * rel_k) / |relevant|   # Mean Average Precision
MRR    = 1/|Q| * Î£(1/rank_i)           # Mean Reciprocal Rank
```

## ğŸ§® Key Algorithms Decision Tree

```
Problem Type?
â”œâ”€â”€ Classification
â”‚   â”œâ”€â”€ Linear Separable? â†’ Logistic Regression, SVM
â”‚   â”œâ”€â”€ Tabular Data? â†’ Random Forest, XGBoost
â”‚   â”œâ”€â”€ High Dimensional? â†’ Naive Bayes, Linear SVM
â”‚   â”œâ”€â”€ Complex Patterns? â†’ Neural Networks
â”‚   â””â”€â”€ Interpretable? â†’ Decision Trees, Logistic Regression
â”‚
â”œâ”€â”€ Regression  
â”‚   â”œâ”€â”€ Linear Relationship? â†’ Linear Regression
â”‚   â”œâ”€â”€ Non-linear? â†’ Polynomial, Kernel Methods
â”‚   â”œâ”€â”€ High Dimensional? â†’ Ridge, Lasso, Elastic Net
â”‚   â”œâ”€â”€ Tabular Data? â†’ Random Forest, XGBoost
â”‚   â””â”€â”€ Complex Patterns? â†’ Neural Networks
â”‚
â”œâ”€â”€ Clustering
â”‚   â”œâ”€â”€ Known K? â†’ K-Means
â”‚   â”œâ”€â”€ Density-based? â†’ DBSCAN
â”‚   â”œâ”€â”€ Hierarchical? â†’ Agglomerative, Divisive
â”‚   â””â”€â”€ High Dimensional? â†’ Spectral Clustering
â”‚
â””â”€â”€ Recommendation
    â”œâ”€â”€ Cold Start? â†’ Content-based, Demographic
    â”œâ”€â”€ Collaborative? â†’ Matrix Factorization, CF
    â”œâ”€â”€ Hybrid? â†’ Weighted, Switching, Mixed
    â””â”€â”€ Real-time? â†’ Two-tower, Candidate Generation
```

## âš¡ Bias-Variance Trade-off

| Aspect | High Bias | High Variance | Balanced |
|--------|-----------|---------------|----------|
| **Model Complexity** | Too Simple | Too Complex | Just Right |
| **Training Error** | High | Low | Medium |
| **Validation Error** | High | High | Low |
| **Symptoms** | Underfitting | Overfitting | Good Generalization |
| **Solutions** | More features, complex model | Regularization, more data | Cross-validation tuning |
| **Examples** | Linear model for non-linear data | Deep NN on small dataset | Properly tuned RF |

## ğŸ”§ System Design Patterns

### Batch vs Real-time Decision Matrix

| Requirement | Batch | Real-time | Hybrid |
|-------------|-------|-----------|---------|
| **Latency** | Hours/Days | <100ms | Mixed |
| **Throughput** | Very High | Medium | High |
| **Cost** | Low | High | Medium |
| **Complexity** | Low | High | Very High |
| **Use Cases** | Recommendations, Reports | Fraud, Ads | Personalization |

### Architecture Components
```mermaid
graph LR
    A[Data Sources] --> B[Feature Store]
    B --> C[Model Training]
    C --> D[Model Registry]
    D --> E[Model Serving]
    E --> F[Prediction API]
    
    G[Monitoring] --> E
    G --> B
    G --> C
```

## ğŸ“ˆ A/B Testing Framework

### Sample Size Calculation
```
n = (Z_Î±/2 + Z_Î²)Â² * 2 * p * (1-p) / (pâ‚-pâ‚€)Â²

Where:
- Z_Î±/2: Critical value for significance level (1.96 for 95%)
- Z_Î²: Critical value for power (0.84 for 80% power)  
- p: Baseline conversion rate
- pâ‚-pâ‚€: Minimum detectable effect
```

### Statistical Tests Quick Reference
| Data Type | Comparison | Test |
|-----------|------------|------|
| Continuous | 2 groups | t-test |
| Continuous | >2 groups | ANOVA |
| Categorical | 2 proportions | Chi-square |
| Non-parametric | 2 groups | Mann-Whitney U |
| Paired | Before/After | Paired t-test |

## ğŸ› Debugging Playbook

### Performance Drop Investigation
```
1. Data Issues
   â”œâ”€â”€ Check feature drift (KS test, PSI)
   â”œâ”€â”€ Verify label quality  
   â”œâ”€â”€ Look for data leakage
   â””â”€â”€ Validate data pipeline

2. Model Issues  
   â”œâ”€â”€ Compare train vs validation performance
   â”œâ”€â”€ Check hyperparameter drift
   â”œâ”€â”€ Verify model serving consistency
   â””â”€â”€ Test feature importance changes

3. System Issues
   â”œâ”€â”€ Monitor latency and throughput
   â”œâ”€â”€ Check cache hit rates
   â”œâ”€â”€ Validate A/B test setup
   â””â”€â”€ Review infrastructure changes
```

### Common ML Failure Modes
| Symptom | Likely Cause | Quick Check | Solution |
|---------|--------------|-------------|----------|
| High Bias | Model too simple | Train error high | More features, complex model |
| High Variance | Overfitting | Large train/val gap | Regularization, more data |
| Label Leakage | Future info in features | Perfect accuracy | Remove leaked features |
| Data Drift | Distribution shift | Feature stats change | Retrain model |
| Serving Skew | Train/serve mismatch | Predictions differ | Fix feature pipeline |

## ğŸ¯ Interview Answer Templates

### Problem Framing Template
```
1. Clarify Business Objective
   - What metric are we optimizing?
   - What are the constraints?
   - What's the success criteria?

2. Define ML Problem  
   - Classification/Regression/Ranking?
   - What's the input/output?
   - What data is available?

3. Success Metrics
   - Online metrics (business KPIs)
   - Offline metrics (ML evaluation)
   - Guardrail metrics (safety)
```

### System Design Template  
```
1. Requirements Gathering
   - Scale (QPS, latency, users)
   - Data characteristics
   - Business constraints

2. High-level Architecture
   - Data pipeline
   - Training system  
   - Serving system
   - Monitoring system

3. Deep Dive Components
   - Feature engineering
   - Model selection
   - Serving infrastructure
   - A/B testing framework

4. Scale & Optimize
   - Bottleneck analysis
   - Caching strategies
   - Distributed systems
```

## ğŸ’¡ Common Formulas

### Information Theory
```
Entropy:     H(X) = -Î£ p(x) * logâ‚‚(p(x))
Mutual Info: I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)
KL Divergence: D_KL(P||Q) = Î£ P(x) * log(P(x)/Q(x))
Cross Entropy: H(P,Q) = -Î£ P(x) * log(Q(x))
```

### Loss Functions
```
MSE:           L = (y - Å·)Â²
MAE:           L = |y - Å·|  
Cross-Entropy: L = -y*log(Å·) - (1-y)*log(1-Å·)
Hinge Loss:    L = max(0, 1 - y*Å·)
Focal Loss:    L = -Î±(1-p_t)^Î³ * log(p_t)
```

### Regularization
```
Ridge (L2):    Î» * Î£ Î¸áµ¢Â²
Lasso (L1):    Î» * Î£ |Î¸áµ¢|
Elastic Net:   Î»â‚ * Î£ |Î¸áµ¢| + Î»â‚‚ * Î£ Î¸áµ¢Â²
Dropout:       Randomly set neurons to 0 with prob p
```

## ğŸ¢ Company-Specific Focus

### Meta/Facebook
- **Focus**: Feed ranking, ads optimization, content understanding
- **Key Topics**: Two-tower models, embedding systems, real-time ML
- **Scale**: Billions of users, <100ms latency requirements

### Google  
- **Focus**: Search relevance, ads auction, YouTube recommendations
- **Key Topics**: Learning to rank, BERT integration, distributed systems
- **Scale**: Global infrastructure, multi-language, diverse queries

### Netflix
- **Focus**: Content recommendation, personalization, A/B testing
- **Key Topics**: Collaborative filtering, cold start, diversity optimization  
- **Scale**: 200M+ subscribers, global content catalog

### Amazon
- **Focus**: Product recommendations, search relevance, supply chain
- **Key Topics**: Real-time personalization, inventory optimization
- **Scale**: E-commerce at global scale, diverse product catalog

### Apple
- **Focus**: On-device ML, privacy-preserving ML, Siri/search
- **Key Topics**: Federated learning, model compression, edge computing
- **Scale**: Billions of devices, privacy constraints

## ğŸ“± Mobile/Quick Access Cards

### Algorithm Comparison (60 seconds)
| Algorithm | Pros | Cons | When to Use |
|-----------|------|------|-------------|
| **Logistic Regression** | Fast, interpretable | Linear only | Baseline, simple problems |
| **Random Forest** | Robust, handles missing data | Can overfit | Tabular data, feature importance |
| **SVM** | Good for high-dim | Slow on large data | Text, high-dimensional |
| **Neural Networks** | Universal approximator | Needs lots of data | Images, text, complex patterns |
| **XGBoost** | High performance | Hyperparameter sensitive | Competitions, structured data |

### Metric Selection (30 seconds)
- **Imbalanced Classification**: Precision, Recall, F1, PR-AUC  
- **Balanced Classification**: Accuracy, ROC-AUC
- **Regression**: MAE (robust), RMSE (penalize outliers)
- **Ranking**: NDCG, MAP (relevance matters)
- **Recommendation**: CTR, Diversity, Coverage

### Red Flags (15 seconds)
- ğŸš¨ Perfect accuracy â†’ Label leakage
- ğŸš¨ Train >> Val performance â†’ Overfitting  
- ğŸš¨ Sudden performance drop â†’ Data drift
- ğŸš¨ High latency spikes â†’ Infrastructure issues
- ğŸš¨ Biased predictions â†’ Fairness problems

---

*Keep this guide handy during interviews for quick reference and confidence boosts!*